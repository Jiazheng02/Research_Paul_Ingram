{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from pptx import Presentation\n",
    "from pptx.enum.shapes import MSO_SHAPE_TYPE\n",
    "from pptx.shapes.connector import Connector\n",
    "from paddleocr import PaddleOCR\n",
    "from ImageProcessor import ImageProcessor\n",
    "\n",
    "class PPTGraphExtractor:\n",
    "    \"\"\"\n",
    "    Extracts text boxes, lines, and relationships from a PowerPoint (.pptx) file.\n",
    "    Uses PPT text if possible; falls back to ImageProcessor when no lines are detected.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, pptx_path, id_path):\n",
    "        \"\"\"\n",
    "        Initializes the extractor.\n",
    "\n",
    "        :param pptx_path: Path to the PowerPoint file (.pptx).\n",
    "        :param id_path: Path to the Excel file mapping names to 'id_ego'.\n",
    "        :param image_processor: ImageProcessor instance for OCR-based extraction.\n",
    "        \"\"\"\n",
    "        self.pptx_path = pptx_path\n",
    "        self.id_path = id_path\n",
    "        self.prs = Presentation(pptx_path)\n",
    "\n",
    "    def extract_node_boxes(self, slide, slide_num):\n",
    "        \"\"\"\n",
    "        Extracts text boxes from a PPT slide and identifies the respondent (title).\n",
    "\n",
    "        :param slide: The slide object.\n",
    "        :param slide_num: The slide number.\n",
    "        :return: Tuple (List of node_boxes, Respondent Name, Node Count)\n",
    "        \"\"\"\n",
    "        node_boxes = []\n",
    "        respondent = None  \n",
    "\n",
    "        def extract_text_from_shape(shape):\n",
    "            \"\"\"Recursively extracts text from shapes, including grouped shapes.\"\"\"\n",
    "            if shape.has_text_frame:\n",
    "                text = shape.text.strip()\n",
    "                if text:\n",
    "                    top, left, right, bottom = shape.top, shape.left, shape.left + shape.width, shape.top + shape.height\n",
    "                    node_boxes.append((slide_num, top, left, right, bottom, text))\n",
    "\n",
    "            # Handle GroupShapes containing multiple text boxes\n",
    "            if shape.shape_type == MSO_SHAPE_TYPE.GROUP:\n",
    "                for sub_shape in shape.shapes:\n",
    "                    extract_text_from_shape(sub_shape)\n",
    "\n",
    "        for shape in slide.shapes:\n",
    "            extract_text_from_shape(shape)\n",
    "\n",
    "        # Identify respondent (top-leftmost text box)\n",
    "        if node_boxes:\n",
    "            name_box = min(node_boxes, key=lambda x: (x[1], x[2]))\n",
    "            if not name_box:  # Ensure name_box is not None\n",
    "                return None\n",
    "            respondent = name_box[5]  \n",
    "            node_boxes.remove(name_box)  \n",
    "\n",
    "        node_boxes.sort(key=lambda x: (x[0], x[1], x[2]))  \n",
    "        return node_boxes, respondent, len(node_boxes)\n",
    "\n",
    "    def extract_lines(self, slide):\n",
    "        \"\"\"\n",
    "        Extracts all lines (connectors) from a PPT slide.\n",
    "\n",
    "        :param slide: The slide object.\n",
    "        :return: Tuple (Dictionary of lines, Total line count)\n",
    "        \"\"\"\n",
    "        lines = {}  \n",
    "\n",
    "        for i, shape in enumerate(slide.shapes):\n",
    "            # Check if the shape is a line (includes arrows and connectors)\n",
    "            if shape.shape_type == MSO_SHAPE_TYPE.LINE:\n",
    "                # Explicitly cast shape to Connector type for clarity\n",
    "\n",
    "                shape: Connector = shape\n",
    "                x1, y1 = shape.begin_x, shape.begin_y\n",
    "                x2, y2 = shape.end_x, shape.end_y\n",
    "                lines[i] = (x1, y1, x2, y2)\n",
    "\n",
    "        return lines, len(lines)\n",
    "\n",
    "    def extract_slide_image(self, slide):\n",
    "        \"\"\"\n",
    "        Extracts an image from a PowerPoint slide and converts it to an OpenCV image.\n",
    "\n",
    "        :param slide: The PowerPoint slide object.\n",
    "        :return: OpenCV image (numpy array) or None if no image found.\n",
    "        \"\"\"\n",
    "        for shape in slide.shapes:\n",
    "            if shape.shape_type == MSO_SHAPE_TYPE.PICTURE:\n",
    "                # Extract image blob from shape\n",
    "                image_stream = io.BytesIO(shape.image.blob)\n",
    "                pil_image = Image.open(image_stream)\n",
    "\n",
    "                # Convert PIL image to OpenCV format\n",
    "                return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        return None  # No image found\n",
    "\n",
    "    def match_lines_to_nodes(self, slide, slide_num):\n",
    "        \"\"\"\n",
    "        Matches each line’s endpoints to the nearest text box.\n",
    "\n",
    "        :param slide: The slide object.\n",
    "        :param slide_num: The slide number.\n",
    "        :return: List of matched relationships (from_text → to_text)\n",
    "        \"\"\"\n",
    "        edges = []  # Stores matched edges (connections) between text boxes\n",
    "        node_boxes, respondent, node_count = self.extract_node_boxes(slide, slide_num)  # Extract nodes with bounding box coordinates\n",
    "        lines, line_count = self.extract_lines(slide)  # Extract lines from the slide and count them\n",
    "\n",
    "        # Create mappings from node_boxes\n",
    "        node_map = {}  # Maps text → (top, left, right, bottom)\n",
    "        node_order = {}  # Maps text → index (ranking order)\n",
    "\n",
    "        for idx, (_, top, left, right, bottom, text) in enumerate(node_boxes):\n",
    "            node_map[text] = (top, left, right, bottom)  # Store bounding box coordinates for each text label\n",
    "            node_order[text] = idx  # Assign index based on sorted order\n",
    "\n",
    "        # Iterate through all detected lines\n",
    "        for line_id, (x1, y1, x2, y2) in lines.items():\n",
    "            from_text, to_text = None, None  # Initialize the closest text boxes for each line\n",
    "            min_distance_from = float(\"inf\")  # Track the minimum distance for the line's start point\n",
    "            min_distance_to = float(\"inf\")  # Track the minimum distance for the line's end point\n",
    "\n",
    "            # Iterate over all nodes to find the closest match for both start and end points\n",
    "            for text, (top, left, right, bottom) in node_map.items():\n",
    "                # Compute the center point of the text box\n",
    "                center_x = (left + right) / 2\n",
    "                center_y = (top + bottom) / 2\n",
    "\n",
    "                # Calculate Euclidean distances between the line endpoints and the text box center\n",
    "                dist_from = ((center_x - x1) ** 2 + (center_y - y1) ** 2) ** 0.5\n",
    "                dist_to = ((center_x - x2) ** 2 + (center_y - y2) ** 2) ** 0.5\n",
    "\n",
    "                # Update the closest matching text box for the start point\n",
    "                if dist_from < min_distance_from:\n",
    "                    from_text = text\n",
    "                    min_distance_from = dist_from\n",
    "\n",
    "                # Update the closest matching text box for the end point\n",
    "                if dist_to < min_distance_to:\n",
    "                    to_text = text\n",
    "                    min_distance_to = dist_to\n",
    "\n",
    "            # Ensure a valid connection (avoid self-connections)\n",
    "            # Reorder nodes to ensure `from_text` appears lower (has a larger Y-coordinate)\n",
    "            # PowerPoint uses an inverted Y-axis, meaning larger Y values are lower on the slide\n",
    "            if from_text and to_text and from_text != to_text:\n",
    "                from_top, _, _, from_bottom = node_map[from_text]\n",
    "                to_top, _, _, to_bottom = node_map[to_text]\n",
    "\n",
    "                # Swap if `to_text` is positioned higher than `from_text`\n",
    "                if to_top > from_top:\n",
    "                    from_text, to_text = to_text, from_text\n",
    "                \n",
    "                edges.append((from_text, to_text))\n",
    "\n",
    "        sorted_edges = sorted(edges, key=lambda edge: (node_order.get(edge[0], float(\"inf\")), \n",
    "                                                       node_order.get(edge[1], float(\"inf\"))))\n",
    "        return sorted_edges, respondent, node_count, line_count\n",
    "\n",
    "    def process_slide(self, slide, slide_num):\n",
    "        \"\"\"\n",
    "        Determines whether to use PPT-based or Image-based extraction.\n",
    "\n",
    "        :param slide: The slide object.\n",
    "        :param slide_num: The slide number.\n",
    "        :return: List of extracted relationships.\n",
    "        \"\"\"\n",
    "        node_boxes, respondent, node_count = self.extract_node_boxes(slide, slide_num)  # Extract nodes with bounding box coordinates\n",
    "        lines, line_count = self.extract_lines(slide)  # Extract lines from the slide and count them\n",
    "\n",
    "        if node_count > 0 and line_count > 0:\n",
    "            return self.match_lines_to_nodes(slide, slide_num)\n",
    "        \n",
    "        elif node_count > 0 and line_count == 0:\n",
    "            return [], respondent, node_count, line_count  # No image found, return empty relationships\n",
    "        \n",
    "        elif node_count == 0 and line_count == 0:\n",
    "            image = self.extract_slide_image(slide)\n",
    "\n",
    "            if image is not None:\n",
    "                image_processor = ImageProcessor(image)\n",
    "                edges = image_processor.match_relationships()\n",
    "                return edges, respondent, node_count, line_count\n",
    "            \n",
    "            else:\n",
    "                return [], [], node_count, line_count  # No image found, return empty relationships\n",
    "\n",
    "    def process_pptx_to_dataframe(self):\n",
    "        \"\"\"\n",
    "        Processes all slides and generates a DataFrame.\n",
    "\n",
    "        :return: DataFrame containing extracted relationships.\n",
    "        \"\"\"\n",
    "        data = []\n",
    "\n",
    "        for slide_num, slide in enumerate(self.prs.slides, start=1):\n",
    "            sorted_edges, respondent, node_count, line_count = self.process_slide(slide, slide_num)\n",
    "            void_edge = int(line_count == 0)\n",
    "\n",
    "            if not respondent:\n",
    "                continue\n",
    "            \n",
    "            if sorted_edges:\n",
    "                for from_text, to_text in sorted_edges:\n",
    "                    data.append([respondent, from_text, to_text, void_edge, slide_num])  # Append relationships to data list   \n",
    "            else:\n",
    "                data.append([respondent, None, None, void_edge, slide_num])            \n",
    "\n",
    "        df = pd.DataFrame(data, columns=['Person Name', 'From', 'To', 'NoMeaningfulEdges', 'Slide Number'])\n",
    "\n",
    "        id_df_map = pd.read_excel(self.id_path).set_index('full name')['id_ego'].to_dict()\n",
    "        df.insert(0, 'id_ego', df['Person Name'].map(id_df_map))\n",
    "\n",
    "        return self.clean_dataframe(df)\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_dataframe(df):\n",
    "        \"\"\"\n",
    "        Cleans text data.\n",
    "\n",
    "        :param df: The input DataFrame.\n",
    "        :return: Cleaned DataFrame.\n",
    "        \"\"\"\n",
    "        df = df.copy()\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df[col] = df[col].astype(str).apply(lambda x: re.sub(r'[\\x00-\\x1F\\x7F]', ' ', x) if pd.notna(x) else x)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_path = \"/Users/jiazhengtian/Desktop/Research/Paul Ingram_25.2.21/values for coding/combined id_ego thru fall 24.xlsx\"\n",
    "pptx_path = \"/Users/jiazhengtian/Desktop/Research/Paul Ingram_25.2.21/CodingPhase1/TestFiles/test.pptx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025/03/19 23:13:24] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/Users/jiazhengtian/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/Users/jiazhengtian/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/Users/jiazhengtian/anaconda3/lib/python3.10/site-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/Users/jiazhengtian/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2025/03/19 23:13:26] ppocr DEBUG: dt_boxes num : 9, elapsed : 0.5710039138793945\n",
      "[2025/03/19 23:13:26] ppocr DEBUG: cls num  : 9, elapsed : 0.11215996742248535\n",
      "[2025/03/19 23:13:27] ppocr DEBUG: rec_res num  : 9, elapsed : 1.0445492267608643\n",
      "[2025/03/19 23:13:28] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, use_mlu=False, use_gcu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/Users/jiazhengtian/.paddleocr/whl/det/en/en_PP-OCRv3_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/Users/jiazhengtian/.paddleocr/whl/rec/en/en_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/Users/jiazhengtian/anaconda3/lib/python3.10/site-packages/paddleocr/ppocr/utils/en_dict.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/Users/jiazhengtian/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, onnx_providers=False, onnx_sess_options=False, return_word_box=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, formula_algorithm='LaTeXOCR', formula_model_dir=None, formula_char_dict_path=None, formula_batch_num=1, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, formula=False, ocr=True, recovery=False, recovery_to_markdown=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='en', det=True, rec=True, type='ocr', savefile=False, ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n",
      "[2025/03/19 23:13:30] ppocr DEBUG: dt_boxes num : 37, elapsed : 0.45366501808166504\n",
      "[2025/03/19 23:13:31] ppocr DEBUG: cls num  : 37, elapsed : 0.35501742362976074\n",
      "[2025/03/19 23:13:37] ppocr DEBUG: rec_res num  : 37, elapsed : 6.147002935409546\n"
     ]
    }
   ],
   "source": [
    "extractor = PPTGraphExtractor(pptx_path, id_path)\n",
    "df = extractor.process_pptx_to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], 'Cameron Eskandari', 8, 0)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.extract_node_boxes(extractor.prs.slides[2], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_ego</th>\n",
       "      <th>Person Name</th>\n",
       "      <th>From</th>\n",
       "      <th>To</th>\n",
       "      <th>NoMeaningfulEdges</th>\n",
       "      <th>Slide Number</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>General Love Friend + Romantic</td>\n",
       "      <td>Serenity</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>Humor</td>\n",
       "      <td>Serenity</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>Intellectualism</td>\n",
       "      <td>Humor</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>Make a Difference</td>\n",
       "      <td>General Love Friend + Romantic</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>Accomplishment</td>\n",
       "      <td>Intellectualism</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>Organization</td>\n",
       "      <td>Make a Difference</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>Discipline</td>\n",
       "      <td>Accomplishment</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>Discipline</td>\n",
       "      <td>Organization</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>General Love Friend + Romantic</td>\n",
       "      <td>Serenity</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>Humor</td>\n",
       "      <td>Serenity</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>Intellectualism</td>\n",
       "      <td>Humor</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>Make a Difference</td>\n",
       "      <td>General Love Friend + Romantic</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>Accomplishment</td>\n",
       "      <td>Intellectualism</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>10512</td>\n",
       "      <td>Bleecker Alexander</td>\n",
       "      <td>Organization</td>\n",
       "      <td>Make a Difference</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>10517</td>\n",
       "      <td>Cameron Eskandari</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>Respect</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>Strong work ethic</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>Integrity</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Motivated</td>\n",
       "      <td>Achievement</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Motivated</td>\n",
       "      <td>Strong work ethic</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Strong work ethic</td>\n",
       "      <td>Family</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Strong work ethic</td>\n",
       "      <td>Achievement</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Strong work ethic</td>\n",
       "      <td>Integrity</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Strong work ethic</td>\n",
       "      <td>Respect</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Integrity</td>\n",
       "      <td>Strong work ethic</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Integrity</td>\n",
       "      <td>Respect</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Integrity</td>\n",
       "      <td>Knowledge</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Respect</td>\n",
       "      <td>Family</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Achievement</td>\n",
       "      <td>Family</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Achievement</td>\n",
       "      <td>Motivated</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Achievement</td>\n",
       "      <td>Strong work ethic</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Family</td>\n",
       "      <td>Respect</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>10576</td>\n",
       "      <td>Laura Tejeda</td>\n",
       "      <td>Family</td>\n",
       "      <td>Happiness</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_ego         Person Name                            From  \\\n",
       "0    10512  Bleecker Alexander  General Love Friend + Romantic   \n",
       "1    10512  Bleecker Alexander                           Humor   \n",
       "2    10512  Bleecker Alexander                 Intellectualism   \n",
       "3    10512  Bleecker Alexander               Make a Difference   \n",
       "4    10512  Bleecker Alexander                  Accomplishment   \n",
       "5    10512  Bleecker Alexander                    Organization   \n",
       "6    10512  Bleecker Alexander                      Discipline   \n",
       "7    10512  Bleecker Alexander                      Discipline   \n",
       "8    10512  Bleecker Alexander  General Love Friend + Romantic   \n",
       "9    10512  Bleecker Alexander                           Humor   \n",
       "10   10512  Bleecker Alexander                 Intellectualism   \n",
       "11   10512  Bleecker Alexander               Make a Difference   \n",
       "12   10512  Bleecker Alexander                  Accomplishment   \n",
       "13   10512  Bleecker Alexander                    Organization   \n",
       "14   10517   Cameron Eskandari                            None   \n",
       "15   10576        Laura Tejeda                       Knowledge   \n",
       "16   10576        Laura Tejeda                       Knowledge   \n",
       "17   10576        Laura Tejeda                       Knowledge   \n",
       "18   10576        Laura Tejeda                       Motivated   \n",
       "19   10576        Laura Tejeda                       Motivated   \n",
       "20   10576        Laura Tejeda               Strong work ethic   \n",
       "21   10576        Laura Tejeda               Strong work ethic   \n",
       "22   10576        Laura Tejeda               Strong work ethic   \n",
       "23   10576        Laura Tejeda               Strong work ethic   \n",
       "24   10576        Laura Tejeda                       Integrity   \n",
       "25   10576        Laura Tejeda                       Integrity   \n",
       "26   10576        Laura Tejeda                       Integrity   \n",
       "27   10576        Laura Tejeda                         Respect   \n",
       "28   10576        Laura Tejeda                     Achievement   \n",
       "29   10576        Laura Tejeda                     Achievement   \n",
       "30   10576        Laura Tejeda                     Achievement   \n",
       "31   10576        Laura Tejeda                          Family   \n",
       "32   10576        Laura Tejeda                          Family   \n",
       "\n",
       "                                To  NoMeaningfulEdges  Slide Number  \n",
       "0                         Serenity                  0             1  \n",
       "1                         Serenity                  0             1  \n",
       "2                            Humor                  0             1  \n",
       "3   General Love Friend + Romantic                  0             1  \n",
       "4                  Intellectualism                  0             1  \n",
       "5                Make a Difference                  0             1  \n",
       "6                   Accomplishment                  0             1  \n",
       "7                     Organization                  0             1  \n",
       "8                         Serenity                  0             2  \n",
       "9                         Serenity                  0             2  \n",
       "10                           Humor                  0             2  \n",
       "11  General Love Friend + Romantic                  0             2  \n",
       "12                 Intellectualism                  0             2  \n",
       "13               Make a Difference                  0             2  \n",
       "14                            None                  1             3  \n",
       "15                         Respect                  1             4  \n",
       "16               Strong work ethic                  1             4  \n",
       "17                       Integrity                  1             4  \n",
       "18                     Achievement                  1             4  \n",
       "19               Strong work ethic                  1             4  \n",
       "20                          Family                  1             4  \n",
       "21                     Achievement                  1             4  \n",
       "22                       Integrity                  1             4  \n",
       "23                         Respect                  1             4  \n",
       "24               Strong work ethic                  1             4  \n",
       "25                         Respect                  1             4  \n",
       "26                       Knowledge                  1             4  \n",
       "27                          Family                  1             4  \n",
       "28                          Family                  1             4  \n",
       "29                       Motivated                  1             4  \n",
       "30               Strong work ethic                  1             4  \n",
       "31                         Respect                  1             4  \n",
       "32                       Happiness                  1             4  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
