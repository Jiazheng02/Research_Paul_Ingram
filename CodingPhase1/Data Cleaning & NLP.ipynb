{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "fae99b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import spacy\n",
    "from spellchecker import SpellChecker\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from nltk.corpus import wordnet\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ebc748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the English NLP model for lemmatization\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load the spell checker\n",
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b7eeea",
   "metadata": {},
   "source": [
    "# Lemmatization（归一化） & Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e64d75f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Lemmatization (Word Form Normalization)\n",
    "def lemmatize_word(word):\n",
    "    \"\"\"Convert a word to its lemma form using spaCy.\"\"\"\n",
    "    doc = nlp(word.lower())  # Convert to lowercase and process with spaCy\n",
    "    return doc[0].lemma_  # Return the lemmatized form of the first token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b8430ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Spelling Correction\n",
    "def correct_spelling(word):\n",
    "    \"\"\"Correct spelling mistakes using SpellChecker.\"\"\"\n",
    "    corrected = spell.correction(word)  # Attempt to correct the spelling\n",
    "    return corrected if corrected else word  # Return corrected word if available, otherwise return original word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9be7796c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Text Cleaning\n",
    "def clean_text(text):\n",
    "    \"\"\"Perform spelling correction on each word in the input text.\"\"\"\n",
    "    words = text.split()  # Split the text into individual words\n",
    "    cleaned_words = []\n",
    "    for word in words:\n",
    "        corrected = correct_spelling(word)  # Perform spelling correction\n",
    "        cleaned_words.append(corrected)  # Append the corrected word to the list\n",
    "    return \" \".join(cleaned_words)  # Reconstruct the cleaned text as a single string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "106bb8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file\n",
    "file_path = \"/Users/jiazhengtian/Desktop/Research/Paul Ingram_25.2.21/Extracted Data/Combined_data.xlsx\"  # Replace with your file path\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "# Apply text cleaning to the \"From\" and \"To\" columns\n",
    "df[\"From_Cleaned\"] = df[\"From\"].astype(str).apply(lambda x: clean_text(x))\n",
    "df[\"To_Cleaned\"] = df[\"To\"].astype(str).apply(lambda x: clean_text(x))\n",
    "\n",
    "df_cleaned = df.copy()\n",
    "df_cleaned.drop(columns=[\"From_Cleaned\", \"To_Cleaned\"], inplace=True)\n",
    "df_cleaned.rename(columns={\"From_Cleaned\": \"From\", \"To_Cleaned\": \"To\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e45f8a",
   "metadata": {},
   "source": [
    "# Values Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "16101813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract unique values from the \"From\" and \"To\" columns\n",
    "values = list(set(df[\"From\"].astype(str)) | set(df[\"To\"].astype(str)))  # Convert to string and deduplicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7238a8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"清理文本：去标点、转换小写、lemmatization\"\"\"\n",
    "    text = text.lower().strip()\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)  # 去掉标点符号\n",
    "    doc = nlp(text)\n",
    "    return \" \".join(sorted([token.lemma_ for token in doc if token.is_alpha]))  # 词形归一化 + 排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "438c2688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_values(df, column_name):\n",
    "    \"\"\"对 DataFrame 某列的短语进行归一化\"\"\"\n",
    "    value_map = {}\n",
    "    unique_values = df[column_name].dropna().astype(str).unique()  # 取唯一值\n",
    "    normalized_dict = defaultdict(list)\n",
    "\n",
    "    # 处理所有唯一值，创建归一化映射\n",
    "    for value in unique_values:\n",
    "        normalized = preprocess_text(value)\n",
    "        normalized_dict[normalized].append(value)  # 归类到相同的 key\n",
    "\n",
    "    # 选择最常见的表达方式作为标准形式\n",
    "    for norm, variations in normalized_dict.items():\n",
    "        standard_value = sorted(variations, key=len)[0]  # 选最短的作为标准\n",
    "        for v in variations:\n",
    "            value_map[v] = standard_value  # 映射到标准表达\n",
    "\n",
    "    # 替换 DataFrame 中的值\n",
    "    df[column_name + \"_Clustering\"] = df[column_name].astype(str).apply(lambda x: value_map.get(x, x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "91f1fb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **对 'From' 和 'To' 列进行归一化**\n",
    "df_cleaned = normalize_values(df_cleaned, \"From\")\n",
    "df_cleaned = normalize_values(df_cleaned, \"To\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5eee7300",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned.to_excel(\"clustered.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ec01f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
